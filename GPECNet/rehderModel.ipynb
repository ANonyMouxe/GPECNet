{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rehderModel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1JNyqndl-_j5NMPS4dnoFi1vdRCaxP9qs","authorship_tag":"ABX9TyP8D3Ado70lzjUVkmxa2Pdi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Rehder on Daimler Implementation\n","---\n","> Aryan Garg  \n","> Dr. Amit S. Unde  \n","> Dr. Renu M. Rameshan  \n"],"metadata":{"id":"glIBKUONGFPI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gT2sVqsE29Yn"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import time\n","import math\n","import scipy.stats as stats\n","from scipy import signal\n","import random\n","\n","\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","import sys\n","\n","from google.colab.patches import cv2_imshow\n","from google.colab import files\n","from PIL import Image\n","\n","import cv2\n","import torch\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import torchvision.transforms as T"]},{"cell_type":"code","source":["class preProcessData:\n","    def readData(self, trainDataP):\n","        try:\n","            self.dirs = [f for f in listdir(trainDataP)]\n","            for directory in self.dirs:\n","                newPath = self.trainDataPath + directory + \"/RectGrabber/\"\n","                files = [f for f in listdir(newPath) if isfile(join(newPath, f))]\n","                self.allTrainingData[directory] = files\n","            #print(self.allTrainingData)\n","            return True\n","        \n","        except Exception as err:\n","            print(err)\n","            print(\"Couldn't read data. Check file paths and file health!\")\n","            return False\n","\n","\n","    def showFrames(self, windowName, imglst):\n","        if len(windowName) != len(imglst):\n","            print(f\"windowName list len: {len(windowName)} not equal to imglst len: {len(imglst)}\")\n","            return False \n","\n","        for i in range(len(windowName)):\n","            cv2_imshow(imglst[i])\n","        \n","        k = cv2.waitKey(0)\n","        if k is not None:\n","            cv2.destroyAllWindows()\n","        \n","        return True\n","        \n","    def showSampleImages(self, folderName = \"2012-06-05_165931\"):\n","        ### TODO: Decrease Image size\n","        print(\"[+] Logging sample images' details\\n---------------------\")\n","        for i in range(1,10,2): \n","            img_left = self.allTrainingData[folderName][i-1]\n","            img_right = self.allTrainingData[folderName][i]\n","\n","            try:\n","                imgL = cv2.imread(self.trainDataPath + folderName + \"/RectGrabber/\" + img_left)\n","                imgR = cv2.imread(self.trainDataPath + folderName + \"/RectGrabber/\" + img_right)\n","                \n","                imgL = cv2.resize(imgL, (600,450))\n","                imgR = cv2.resize(imgR, (600,450))\n","                print(f\"{(i//2) + 1}. Image names: {img_left} & {img_right}\\n\\t\\tShape-L: {imgL.shape}     Shape-R: {imgR.shape}\\n\")\n","                \n","                if not self.showFrames([\"Left frame\", \"Right frame\"], [imgL, imgR]):\n","                    print(f\"Couldn't show sample images from showSampleImages function\")\n","            \n","            except Exception as err:\n","                print(err)\n","                if imgL is None:\n","                    print(f\"[!]Couldn't load L-image: {img_left}\")\n","                if imgR is None:\n","                    print(f\"[!]Couldn't load R-image: {img_right}\")\n","                continue\n","                \n","        print(\"---------------------\\n[+] Finished viewing initial samples.\")\n","\n","\n","    def frameFromLR(self):\n","        ### TODO: Will have to refer to the 14th paper later\n","        pass\n","    \n","\n","    def removeNoise(self):\n","        ### TODO: Future optimization\n","        pass\n","\n","\n","    def detectPedestriansAnnotations(self, dirName, imageList):\n","        '''\n","            Brief: Making bounding boxes using the annotations provided in dataset\n","            Need to use SQL queries here to extract info!!! (.db files are present)\n","        '''\n","        print(\"\\nCreating Bounding Boxes...\")\n","        print(f\"\\nDRAWING FOR {dirName}\")\n","        path_ = \"/content/drive/MyDrive/Trajectory_Res/Dataset/Dataset_Dailmer/TrainingData_Annotations/\"\n","        path_ += str(dirName)+\"/LabelData/\"\n","        # creating file path\n","        dbfile = path_ + \"meas.db\"\n","        \n","        toRet = []\n","        with open(dbfile) as f:\n","            \n","            rd = f.readlines()\n","            # Text formatting params:\n","            font                   = cv2.FONT_HERSHEY_COMPLEX_SMALL\n","            fontScale              = 0.7\n","            fontColor              = (255, 255, 255)\n","            lineType               = 2\n","            for i in range(len(rd)):\n","                imgName = \"\"\n","                box_cos = \"\"\n","                \n","                if \"img\" in rd[i]:\n","                    imgName = rd[i][:-1]\n","                    \n","                    if i+6 < len(rd):\n","                        box_cos = rd[i+6].split()\n","                        if len(box_cos) != 4:\n","                            continue\n","                    else:\n","                        continue\n","                    \n","                    imgName = \"imgrect_\"+imgName[4:] \n","                    #print(f\"{imgName}:{box_cos}\")\n","                    \n","                    img = cv2.imread( \"/content/drive/MyDrive/Trajectory_Res/Dataset/Dataset_Dailmer/Data/TrainingData/\" \n","                                     + dirName + \"/RectGrabber/\" + imgName )\n","                    \n","                    if img is None:\n","                        print(\"[-]Image could not load!\")\n","                        continue\n","\n","                    box_cos = [int(e) for e in box_cos]\n","\n","                    if dirName not in self.detectedDataBox:\n","                        self.detectedDataBox[dirName] = []\n","                        \n","                    self.detectedDataBox[dirName].append(box_cos) \n","                    x,y,a,b = box_cos # Top left: (x,y) ; Bottom Right: (a,b)\n","                    cv2.rectangle(img, (x, y), (a,b), (0, 255, 0), 2)\n","                    #cv2.putText(img,'Person', (int(x),int(y)), font, fontScale,fontColor,lineType)\n","                    #cv2_imshow(img)\n","                    #cv2.waitKey(0)\n","                    toRet.append(img)\n","            \n","            f.close()\n","            return toRet\n","\n","    def saveJPG_for_ViPDL(self, folderName):\n","        for filee in self.allTrainingData[folderName]:\n","            fileP = self.trainDataPath + str(folderName) + \"/RectGrabber/\"\n","            from pathlib import Path\n","            gray = Image.open(Path(fileP) / filee)\n","            gray_img = T.Grayscale(num_output_channels=3)(gray) # convert to 3 channels for ViPDL Panoptic segmentation\n","            #plt.imshow(np.asarray(gray_img))\n","            \n","            if os.path.exists(f'/content/drive/MyDrive/Trajectory_Res/JPGs/{folderName}') == False:\n","              os.mkdir(f'/content/drive/MyDrive/Trajectory_Res/JPGs/{folderName}')\n","\n","            new_file = f\"/content/drive/MyDrive/Trajectory_Res/JPGs/{folderName}/{filee[:-4]}.jpg\"\n","            cv2.imwrite(new_file, np.asarray(gray_img))\n","    \n","    def __init__(self):\n","        self.trainDataPath = \"/content/drive/MyDrive/Trajectory_Res/Dataset/Dataset_Dailmer/Data/TrainingData/\"\n","        self.dirs = []\n","        self.allTrainingData = dict()\n","        if self.readData(self.trainDataPath):\n","            #self.showSampleImages()\n","            self.detectedData = {}\n","            self.detectedDataBox = {} # Contains TL&BR co-ordinates of BB box/frame (directory-wise)\n","            doOneDir = True\n","            for key in self.allTrainingData:\n","                if doOneDir:\n","                    self.detectedData[key] = self.detectPedestriansAnnotations(key, self.allTrainingData[key])\n","                    #self.saveJPG_for_ViPDL(key)\n","                    break\n","                else:\n","                    self.detectedData[key] = self.detectPedestriansAnnotations(key, self.allTrainingData[key])\n","                    cv2.destroyAllWindows()"],"metadata":{"id":"xySGSMcB3kw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = preProcessData()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zI5kCedl470z","executionInfo":{"status":"ok","timestamp":1640477396071,"user_tz":-330,"elapsed":9903,"user":{"displayName":"Aryan Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxEm9W_gQJSfuhHh5FKRI2VybwDBrQ04shgiOH=s64","userId":"14273328435346277708"}},"outputId":"0f086f53-bea4-4081-80bd-0ae6338f7fa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Creating Bounding Boxes...\n","\n","DRAWING FOR 2012-10-11_145520\n"]}]},{"cell_type":"markdown","source":["## ViPDL2 panoptic segmentation ✅\n","---\n","\n","*Using the standard pre-trained resnet50_beta or ViP deeplab trained on\n","cityscapes dataset (frozen weights)*\n","\n"],"metadata":{"id":"jQ1jeGc-DIFr"}},{"cell_type":"code","source":["import collections\n","import tempfile\n","\n","from matplotlib import gridspec\n","import urllib\n","\n","import tensorflow as tf"],"metadata":{"id":"NqV9DCHyAf0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DatasetInfo = collections.namedtuple(\n","    'DatasetInfo',\n","    'num_classes, label_divisor, thing_list, colormap, class_names')\n","\n","\n","def _cityscapes_label_colormap():\n","  \"\"\"Creates a label colormap used in CITYSCAPES segmentation benchmark.\n","\n","  See more about CITYSCAPES dataset at https://www.cityscapes-dataset.com/\n","  M. Cordts, et al. \"The Cityscapes Dataset for Semantic Urban Scene Understanding.\" CVPR. 2016.\n","\n","  Returns:\n","    A 2-D numpy array with each row being mapped RGB color (in uint8 range).\n","  \"\"\"\n","  colormap = np.zeros((256, 3), dtype=np.uint8)\n","  colormap[0] = [128, 64, 128]\n","  colormap[1] = [244, 35, 232]\n","  colormap[2] = [70, 70, 70]\n","  colormap[3] = [102, 102, 156]\n","  colormap[4] = [190, 153, 153]\n","  colormap[5] = [153, 153, 153]\n","  colormap[6] = [250, 170, 30]\n","  colormap[7] = [220, 220, 0]\n","  colormap[8] = [107, 142, 35]\n","  colormap[9] = [152, 251, 152]\n","  colormap[10] = [70, 130, 180]\n","  colormap[11] = [220, 20, 60]\n","  colormap[12] = [255, 0, 0]\n","  colormap[13] = [0, 0, 142]\n","  colormap[14] = [0, 0, 70]\n","  colormap[15] = [0, 60, 100]\n","  colormap[16] = [0, 80, 100]\n","  colormap[17] = [0, 0, 230]\n","  colormap[18] = [119, 11, 32]\n","  return colormap\n","\n","\n","def _cityscapes_class_names():\n","  return ('road', 'sidewalk', 'building', 'wall', 'fence', 'pole',\n","          'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky',\n","          'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle',\n","          'bicycle')\n","\n","\n","def cityscapes_dataset_information():\n","  return DatasetInfo(\n","      num_classes=19,\n","      label_divisor=1000,\n","      thing_list=tuple(range(11, 19)),\n","      colormap=_cityscapes_label_colormap(),\n","      class_names=_cityscapes_class_names())\n","\n","\n","def perturb_color(color, noise, used_colors, max_trials=50, random_state=None):\n","  \"\"\"Pertrubs the color with some noise.\n","\n","  If `used_colors` is not None, we will return the color that has\n","  not appeared before in it.\n","\n","  Args:\n","    color: A numpy array with three elements [R, G, B].\n","    noise: Integer, specifying the amount of perturbing noise (in uint8 range).\n","    used_colors: A set, used to keep track of used colors.\n","    max_trials: An integer, maximum trials to generate random color.\n","    random_state: An optional np.random.RandomState. If passed, will be used to\n","      generate random numbers.\n","\n","  Returns:\n","    A perturbed color that has not appeared in used_colors.\n","  \"\"\"\n","  if random_state is None:\n","    random_state = np.random\n","\n","  for _ in range(max_trials):\n","    random_color = color + random_state.randint(\n","        low=-noise, high=noise + 1, size=3)\n","    random_color = np.clip(random_color, 0, 255)\n","\n","    if tuple(random_color) not in used_colors:\n","      used_colors.add(tuple(random_color))\n","      return random_color\n","\n","  print('Max trial reached and duplicate color will be used. Please consider '\n","        'increase noise in `perturb_color()`.')\n","  return random_color\n","\n","\n","def color_panoptic_map(panoptic_prediction, dataset_info, perturb_noise):\n","  \"\"\"Helper method to colorize output panoptic map.\n","\n","  Args:\n","    panoptic_prediction: A 2D numpy array, panoptic prediction from deeplab\n","      model.\n","    dataset_info: A DatasetInfo object, dataset associated to the model.\n","    perturb_noise: Integer, the amount of noise (in uint8 range) added to each\n","      instance of the same semantic class.\n","\n","  Returns:\n","    colored_panoptic_map: A 3D numpy array with last dimension of 3, colored\n","      panoptic prediction map.\n","    used_colors: A dictionary mapping semantic_ids to a set of colors used\n","      in `colored_panoptic_map`.\n","  \"\"\"\n","  if panoptic_prediction.ndim != 2:\n","    raise ValueError('Expect 2-D panoptic prediction. Got {}'.format(\n","        panoptic_prediction.shape))\n","\n","  semantic_map = panoptic_prediction // dataset_info.label_divisor\n","  instance_map = panoptic_prediction % dataset_info.label_divisor\n","  height, width = panoptic_prediction.shape\n","  colored_panoptic_map = np.zeros((height, width, 3), dtype=np.uint8)\n","\n","  used_colors = collections.defaultdict(set)\n","  # Use a fixed seed to reproduce the same visualization.\n","  random_state = np.random.RandomState(0)\n","\n","  unique_semantic_ids = np.unique(semantic_map)\n","  for semantic_id in unique_semantic_ids:\n","    semantic_mask = semantic_map == semantic_id\n","    if semantic_id in dataset_info.thing_list:\n","      # For `thing` class, we will add a small amount of random noise to its\n","      # correspondingly predefined semantic segmentation colormap.\n","      unique_instance_ids = np.unique(instance_map[semantic_mask])\n","      for instance_id in unique_instance_ids:\n","        instance_mask = np.logical_and(semantic_mask,\n","                                       instance_map == instance_id)\n","        random_color = perturb_color(\n","            dataset_info.colormap[semantic_id],\n","            perturb_noise,\n","            used_colors[semantic_id],\n","            random_state=random_state)\n","        colored_panoptic_map[instance_mask] = random_color\n","    else:\n","      # For `stuff` class, we use the defined semantic color.\n","      colored_panoptic_map[semantic_mask] = dataset_info.colormap[semantic_id]\n","      used_colors[semantic_id].add(tuple(dataset_info.colormap[semantic_id]))\n","  return colored_panoptic_map, used_colors\n","\n","\n","def vis_segmentation(image,\n","                     panoptic_prediction,\n","                     dataset_info,\n","                     perturb_noise=60):\n","  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n","  plt.figure(figsize=(30, 20))\n","  grid_spec = gridspec.GridSpec(2, 2)\n","\n","  ax = plt.subplot(grid_spec[0])\n","  plt.imshow(image)\n","  plt.axis('off')\n","  ax.set_title('input image', fontsize=20)\n","\n","  ax = plt.subplot(grid_spec[1])\n","  panoptic_map, used_colors = color_panoptic_map(panoptic_prediction,\n","                                                 dataset_info, perturb_noise)\n","  plt.imshow(panoptic_map)\n","  plt.axis('off')\n","  ax.set_title('panoptic map', fontsize=20)\n","\n","  ax = plt.subplot(grid_spec[2])\n","  plt.imshow(image)\n","  plt.imshow(panoptic_map, alpha=0.7)\n","  plt.axis('off')\n","  ax.set_title('panoptic overlay', fontsize=20)\n","\n","  ax = plt.subplot(grid_spec[3])\n","  max_num_instances = max(len(color) for color in used_colors.values())\n","  # RGBA image as legend.\n","  legend = np.zeros((len(used_colors), max_num_instances, 4), dtype=np.uint8)\n","  class_names = []\n","  for i, semantic_id in enumerate(sorted(used_colors)):\n","    legend[i, :len(used_colors[semantic_id]), :3] = np.array(\n","        list(used_colors[semantic_id]))\n","    legend[i, :len(used_colors[semantic_id]), 3] = 255\n","    if semantic_id < dataset_info.num_classes:\n","      class_names.append(dataset_info.class_names[semantic_id])\n","    else:\n","      class_names.append('ignore')\n","\n","  plt.imshow(legend, interpolation='nearest')\n","  ax.yaxis.tick_left()\n","  plt.yticks(range(len(legend)), class_names, fontsize=15)\n","  plt.xticks([], [])\n","  ax.tick_params(width=0.0, grid_linewidth=0.0)\n","  plt.grid('off')\n","  plt.show()"],"metadata":{"id":"vab_Dov6Glul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = 'resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model'  # @param ['resnet50_os32_panoptic_deeplab_cityscapes_crowd_trainfine_saved_model', 'resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model', 'wide_resnet41_os16_panoptic_deeplab_cityscapes_trainfine_saved_model', 'swidernet_sac_1_1_1_os16_panoptic_deeplab_cityscapes_trainfine_saved_model', 'swidernet_sac_1_1_3_os16_panoptic_deeplab_cityscapes_trainfine_saved_model', 'swidernet_sac_1_1_4.5_os16_panoptic_deeplab_cityscapes_trainfine_saved_model', 'axial_swidernet_1_1_1_os16_axial_deeplab_cityscapes_trainfine_saved_model', 'axial_swidernet_1_1_3_os16_axial_deeplab_cityscapes_trainfine_saved_model', 'axial_swidernet_1_1_4.5_os16_axial_deeplab_cityscapes_trainfine_saved_model', 'max_deeplab_s_backbone_os16_axial_deeplab_cityscapes_trainfine_saved_model', 'max_deeplab_l_backbone_os16_axial_deeplab_cityscapes_trainfine_saved_model']\n","\n","\n","_MODELS = ('resnet50_os32_panoptic_deeplab_cityscapes_crowd_trainfine_saved_model',\n","           'resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model',\n","           'wide_resnet41_os16_panoptic_deeplab_cityscapes_trainfine_saved_model',\n","           'swidernet_sac_1_1_1_os16_panoptic_deeplab_cityscapes_trainfine_saved_model',\n","           'swidernet_sac_1_1_3_os16_panoptic_deeplab_cityscapes_trainfine_saved_model',\n","           'swidernet_sac_1_1_4.5_os16_panoptic_deeplab_cityscapes_trainfine_saved_model',\n","           'axial_swidernet_1_1_1_os16_axial_deeplab_cityscapes_trainfine_saved_model',\n","           'axial_swidernet_1_1_3_os16_axial_deeplab_cityscapes_trainfine_saved_model',\n","           'axial_swidernet_1_1_4.5_os16_axial_deeplab_cityscapes_trainfine_saved_model',\n","           'max_deeplab_s_backbone_os16_axial_deeplab_cityscapes_trainfine_saved_model',\n","           'max_deeplab_l_backbone_os16_axial_deeplab_cityscapes_trainfine_saved_model')\n","_DOWNLOAD_URL_PATTERN = 'https://storage.googleapis.com/gresearch/tf-deeplab/saved_model/%s.tar.gz'\n","\n","_MODEL_NAME_TO_URL_AND_DATASET = {\n","    model: (_DOWNLOAD_URL_PATTERN % model, cityscapes_dataset_information())\n","    for model in _MODELS\n","}\n","\n","MODEL_URL, DATASET_INFO = _MODEL_NAME_TO_URL_AND_DATASET[MODEL_NAME]"],"metadata":{"id":"7ghjy_HYGm0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_dir = tempfile.mkdtemp()\n","\n","download_path = os.path.join(model_dir, MODEL_NAME + '.gz')\n","urllib.request.urlretrieve(MODEL_URL, download_path)\n","\n","!tar -xzvf {download_path} -C {model_dir}\n","\n","LOADED_MODEL = tf.saved_model.load(os.path.join(model_dir, MODEL_NAME))"],"metadata":{"id":"vmKQkFn2Hem_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640478147657,"user_tz":-330,"elapsed":43385,"user":{"displayName":"Aryan Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxEm9W_gQJSfuhHh5FKRI2VybwDBrQ04shgiOH=s64","userId":"14273328435346277708"}},"outputId":"b31c02a5-ad42-4829-e603-591ecebbf2e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/\n","resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/assets/\n","resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/saved_model.pb\n","resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/variables/\n","resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/variables/variables.data-00000-of-00001\n","resnet50_beta_os32_panoptic_deeplab_cityscapes_trainfine_saved_model/variables/variables.index\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_40996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_17660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_46688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_19354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_25698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_23252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_23736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_41256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage3_layer_call_and_return_conditional_losses_33496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_18144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_16182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_15698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage5_layer_call_and_return_conditional_losses_114739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_39544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_20348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_42242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_22768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_14233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_45182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_17418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_19609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_43712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_42000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_20832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_40270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_15214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_41740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stem_layer_call_and_return_conditional_losses_34950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage4_layer_call_and_return_conditional_losses_32098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_44698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_PanopticDeepLab_layer_call_and_return_conditional_losses_53364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_42986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_21558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_14972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_13736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage5_layer_call_and_return_conditional_losses_30244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_21074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_18628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_DeepLab_layer_call_and_return_conditional_losses_77885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_24730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_15940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage4_layer_call_and_return_conditional_losses_113365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_45944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_18386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_13252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_127119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_14730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_24972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_115745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_42502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_18870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_41498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_40028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_115608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stem_layer_call_and_return_conditional_losses_107635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_44940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_39786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage3_layer_call_and_return_conditional_losses_110785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_20106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_13494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_25940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage2_layer_call_and_return_conditional_losses_34561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_PanopticDeepLab_layer_call_and_return_conditional_losses_107217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_DeepLab_layer_call_and_return_conditional_losses_87885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stage2_layer_call_and_return_conditional_losses_109009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_16437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_46446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_22042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_resnet50_beta_layer_call_and_return_conditional_losses_102531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_127250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_19851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_115471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_40512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_127376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_22526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_46186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_25214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_13010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_26182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_43954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_24475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_19112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_16679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_23978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_23494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_43228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_22284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_21800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_21316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_resnet50_beta_layer_call_and_return_conditional_losses_96523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_117267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_15456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_45442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_122199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_20590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_17902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_23010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_45684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_16934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_119322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_120966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_44196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_25456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_118500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_42744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_123158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_116856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_125286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_14488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_44438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_13991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_124892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_24233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_121651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_40754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_43470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_17176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batch_norm_layer_call_and_return_conditional_losses_126605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"]}]},{"cell_type":"markdown","source":["# Stream Data In & Out from JPGs dir\n","---\n","Future:\n","*   Pre-compute all environment maps. (ViPDL2 fps: 5) OR\n","*   **Replace Segmentation algorithm with a faster one and make everything real-time**\n","\n","\n","\n"],"metadata":{"id":"hscKy9rOHiQd"}},{"cell_type":"code","source":["def segment_Image(imgPath = ''):\n","  UPLOADED_FILE = imgPath\n","  with tf.io.gfile.GFile(UPLOADED_FILE, 'rb') as f:\n","    im = np.array(Image.open(f))\n","\n","  output = LOADED_MODEL(tf.cast(im, tf.uint8))\n","  #vis_segmentation(im, output['panoptic_pred'][0], DATASET_INFO)\n","  return output['semantic_probs'][0] # This is THETA -> ENV_MAP\n"],"metadata":{"id":"1O-XLuQaIR8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env_map = segment_Image(\"/content/imgrect_000000163_c0.jpg\")"],"metadata":{"id":"b4Hh1FUHHoQB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Segmentation Done! ⭐\n","---\n","# Moving on to the main Prediction Model"],"metadata":{"id":"xYzkr7ELIclS"}},{"cell_type":"code","source":["class model:\n","    '''\n","    Brief:\n","        Goal Directed Pedestrian Prediction \n","        (A markovian approach for pedestrian trajectory prediction)\n","        \n","    Receives:\n","        Pre-processed and pedestrain detected data from preProcessData class\n","        \n","    Returns:\n","        Predicted Trajectory of each pedestrian in scene\n","                \n","    '''\n","    \n","    # State Transition stuff ahead:\n","    def compute_X(self, dirName = '2012-04-02_115542', numFramesToObserve = 30):\n","        # COMPUTING ONLY FOR THE TL PIXEL OF RECTANGLE \n","        for i in range(1, numFramesToObserve):\n","            x1, y1, a1, b1 = self.dfBox[dirName][i-1]\n","            x2, y2, a2, b2 = self.dfBox[dirName][i]\n","            vx = (x2 - x1) * self.fps    # TODO: Use more valid points to compute an average velocity\n","            vy = (y2 - y1) * self.fps\n","            #print(f\"*** Frames {i-1} and {i} ***\\nvx: {vx} px/sec\\nvy: {vy} px/sec\")\n","            psi = 0\n","            if (x2-x1) != 0:\n","                psi = math.atan2(  (y2-y1) , (x2-x1) ) # Slope \n","            #print(f\"phi_t: {math.degrees(psi)} degrees\\n\")\n","            self.uni.append([vx, vy, 0])\n","            self.X.append([x1 + vx/self.fps, y1 + vy/self.fps, 0 + psi]) # Xt = Xt-1 + u(v_t, psi_t) \n","        self.eq3_dist_X()\n","        #self.get_XTs()\n","    \n","    def eq3_dist_X(self):\n","        '''\n","            phi_t = p( X_t | X_t-1 )\n","            p(Xt|Xt−1) = p(Xt−1) ⊗ p(u(vt, ψt))\n","        '''\n","        self.distX = np.zeros(shape=(640, 1176))\n","        n = len(self.X)\n","        \n","        for i in range(n):\n","            self.distX[int(self.X[i][1])][int(self.X[i][0])] += 1 / n\n","        \n","        #print(self.distX)\n","        #print(self.distUni)\n","        \n","        #plt.subplot(1,2,1)\n","        #plt.imshow(self.distX)\n","        #plt.subplot(1,2,2)\n","        #plt.imshow(self.distUni)\n","        #plt.show()\n","        # Convolve the two grid distributions\n","        #self.Xt_given_Xt_1 = conv_pmf = signal.fftconvolve(self.distX, self.distUni, 'same')\n","        \n","        #print(f\"P(Xt|Xt-1) = P(Xt-1) * p(u(vt,psit)) =\\n{self.Xt_given_Xt_1}\")\n","        \n","        #for i in range(640):\n","        #    for j in range(1176):           \n","        #        if self.Xt_given_Xt_1[i][j] >= 1:\n","        #            print(f\"cell({i},{j})'s p(Xt|Xt-1) = {self.Xt_given_Xt_1[i][j]}\\nNOT POSSIBLE! RE-CHECK CONVOLUTION\")\n","                \n","        #plt.imshow(disp)\n","        #plt.show()\n","        self.eq4()\n","    \n","    def discretization_2_grid(self, p, x, y):\n","        '''\n","            Consider 1x1 cells -> assign probability(from incremental distribution) to each cell\n","            At the end: A (the convolution filter mask) is obtained \n","        '''\n","        self.A[int(y)][int(x)] = p\n","        \n","    \n","    \n","    def mean_var(self, samples):\n","        mean = sum(samples) / len(samples)\n","        var = 0\n","        for e in samples:\n","            var += (e - mean)**2\n","        var /= len(samples)-1 \n","        return mean, var\n","    \n","    \n","    def vonMises(self, samples):\n","        R = 0                      # 1/N * Summation{e^i.\\theta}\n","        for i in range(len(samples)):\n","            R += math.cos((i+1)*samples[i]) + 1j*math.sin((i+1)*samples[i])\n","        \n","        Rbar = np.abs(R)/len(samples)\n","        kappa_v = (2*Rbar - (Rbar**3)) / (1 - (Rbar**2)) # This is an approximation for fast computation only!\n","        \n","        # TODO: Find closer approximation from Bessel function or Ap^-1\n","        return Rbar, kappa_v\n","    \n","    \n","    def eq4(self):\n","        '''\n","        Model the incremental distribution:\n","            This is p(u(v, psi)) effectively...\n","            \n","            p(∆x, ∆y, ∆ψ) ∝  exp(−(∆x−∆tv cos(ψ))^2/2σ_v^2)\n","                            .exp(−(∆y−∆tv sin(ψ))^2/2σ_v^2)\n","                            .exp(κ∆ψ cos(∆ψ))\n","                            .exp(κv cos(∠(∆y, ∆x) − ψ))\n","                            \n","        Then call self.discretization_2_grid() to get A (the convolution filter mask)\n","        Then call eq5 to get phi_t using A and phi_t-1\n","        \n","        v   -> Normal Dist.             \n","        psi -> circular Normal Dist.\n","        '''\n","        # p[x][y][psi] = model it!!!\n","        vx_mu, vx_var = self.mean_var([e[0] for e in self.uni])\n","        vy_mu, vy_var = self.mean_var([e[1] for e in self.uni])\n","        psi_mu, psi_kappa = self.vonMises([e[2] for e in self.X])\n","        \n","        kappa_nonAligned = 1   # TODO: Figure out if this can be found from the data or is a free parameter\n","        \n","        # TODO: Now find p(del_x, del_y, del_psi)\n","        x,y,z = self.X[-1] # Get filter: A, from last observed position-orientation tuple\n","        # Keeping to a region of -20 to +20\n","        for i in range(-50, 51):\n","            for j in range(-50, 51):\n","                xprev = x + i\n","                yprev = y + j\n","                if i != 0:\n","                    zprev = z - math.atan2((y - yprev),(x - xprev))\n","                else:\n","                    if y - yprev < 0:\n","                        zprev = z + math.pi/2\n","                    else:\n","                        zprev = z - math.pi/2\n","        \n","                # Constant of proportionality  \n","                from scipy.special import kn\n","                k = 8*(math.pi**3)*math.sqrt(vx_var)*math.sqrt(vy_var)*kn(0, psi_kappa)*kn(0, kappa_nonAligned) \n","                \n","                P_del_xyz = 1/k\n","                P_del_xyz *= math.exp(-(((x-xprev) - vx_mu/self.fps)**2)/(2*vx_var)) \n","                #print(self.P_delDist, math.exp(-(((x-xprev) - vx_mu/self.fps)**2)/(2*vx_var)) )\n","                P_del_xyz *= math.exp(-(((y-yprev) - vy_mu/self.fps)**2)/(2*vy_var)) \n","                #print(self.P_delDist,  math.exp(-(((y-yprev) - vy_mu/self.fps)**2)/(2*vy_var)))\n","                \n","                P_del_xyz *= math.exp(psi_kappa * math.cos(z - zprev))\n","                #print(self.P_delDist, psi_kappa )\n","                \n","                angle = 0 # goes in non-alaigned term\n","                if  x-xprev == 0:\n","                    angle = math.pi/2 # arctan(infinity) is pi/2\n","                    if y - yprev < 0:\n","                        angle *= -1 # arctan(-inf) is -pi/2\n","                else:    \n","                    angle = math.atan2((y-yprev),(x-xprev))\n","                \n","                P_del_xyz *= math.exp( kappa_nonAligned * math.cos(angle - z) )\n","                #print(P_del_xyz,  math.exp( kappa_nonAligned * math.cos(angle - z)))\n","                self.discretization_2_grid(P_del_xyz, x+i, y+j)                      \n","        print(f\"Filter A computed!\")\n","        \n","        # Normalize to be double sure! \n","        xmax, xmin = self.A.max(), self.A.min()\n","        self.A = (self.A - xmin)/(xmax - xmin)\n","        \n","        plt.figure(figsize = (16,12))\n","        plt.title(\"Filter A\")\n","        plt.imshow(self.A, cmap='hot', interpolation='nearest')\n","        plt.show()\n","        self.eq5()\n","        \n","    \n","    def eq5(self):\n","        '''\n","            Φt ∝ A ⊗ Φt−1\n","            where Φt = P( Xt | Xt-1 ) {contained in self.Xt_given_Xt_1} \n","            Convolve here\n","            \n","            Do something like:\n","            #self.Xt_given_Xt_1 = conv_pmf = signal.fftconvolve(self.distX, self.A, 'same')\n","        '''\n","        self.Xt_given_Xt_1 = signal.fftconvolve(self.distX, self.A, 'same')\n","        self.get_XTs()\n","        \n","    \n","    def get_XTs(self): # Adaptive? Monte Carlo Simulation\n","        if self.XT == None: # Uniform sampling \n","            self.XT = dict()\n","            centerX, centerY, z = self.X[-1]\n","            # Create 100 particles at a distance of 100 pixels uniformly distributed\n","            self.XT[0] = []\n","            for i in range(500):\n","                r = random.randint(10,400) * math.sqrt(random.random())\n","                theta = random.random() * 2 * math.pi\n","                x = centerX + r * math.cos(theta)\n","                y = 640 - centerY + r * math.sin(theta)\n","                if x <= 640 and y <= 1176 and y >= 0 and x >= 0:\n","                  self.XT[0].append((int(x),int(y)))\n","        else: # Resample according to previous distribution\n","            # GMM Stuff\n","            pass\n","        self.eq7()\n","    \n","    \n","    def eq7(self):\n","        '''\n","            Carry out forward and backward steps to get each p(Xt | X0, XT) acc. to:\n","            p(Xt|X0, XT ) ∝ Φ+t Φ−t\n","        '''\n","        predStep = self.eq8() * self.eq9(phi_minus_t)\n","    \n","    \n","    # Location Prior stuff also needed for eq8 and 9\n","    def eq8(self):\n","        '''\n","            Forward step:\n","            Φ+t ∝ p(Xt|Θt)(A ⊗ Φ+t−1)\n","            \n","            where Θt is the online map\n","                  p(X|θi) is the location prior (call eq10 here)\n","        '''\n","        phi_plus_t = self.Xt_given_Xt_1 * self.eq10() # Forward step prediction: Done\n","        return phi_plus_t\n","    \n","    def eq9(self, phi_minus_t):\n","        '''\n","            Backward step:\n","            Φ−t−1 ∝ p(Xt|Θt)(A^(−1) ⊗ Φ−t)\n","            \n","            call eq10 from here\n","        '''\n","        phi_minus_tM1 = self.eq10() * signal.fftconvolve(np.linalg.inv(self.A), phi_minus_t, 'same')\n","        return phi_minus_tM1\n","    \n","    def SLP(self, weights, x, whatPhase):\n","      '''\n","        x -> semantic map (640, 1176, 19)\n","      '''\n","      def forwardpass(self, x, weights):\n","        # output = 1 / 1 + exp(-weights^T(1x19) * input vec(19x1))\n","        return 1 / 1 + math.exp(-self.weights.T @ x)\n","\n","      def activation(self, num):\n","        return num\n","\n","      def update(self, x, ytrue):\n","        err = ytrue - activation(self.forwardpass(x))\n","        self.weights = self.weights + learningRate * err * x\n","        return abs(err)\n","\n","      def loss(self, iter):\n","        if iter % 100 == 0:\n","          print(f\"epoch {int(iter/100 + 1)}/{int(len(trainY)/100)} ======> Absolute Loss = {round(self.lossVal/(iter+1), 3)}\")\n","\n","      if whatPhase is 'train':\n","        trainY = []\n","        ytrue = []\n","        learningRate = 0.5\n","        pass\n","      else:\n","        return activation(forwardpass(x, weights))\n","    \n","    def eq10(self, imgPath):\n","        '''\n","            Computes Location prior: p(X|θi) acc to:\n","            \n","            Single Layer Perceptron: \n","            p(X|θi) = 1 / 1 + exp (−a^T . θ_i)\n","            \n","            where a^T represents weighting params for different features. \n","            \n","            Labels:\n","            'road', 'sidewalk', 'building', 'wall', 'fence', 'pole',\n","            'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky',\n","            'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle',\n","            'bicycle'\n","\n","        '''\n","        THETA = segment_Image()\n","        a = np.zeros((19,1))\n","        a[0] = 0.45\n","        a[1] = 0.42\n","        a[9] = 0.1\n","        a[15] = 0.03\n","        self.SLP(a, 'train')\n","        locationPrior = np.zeros((640, 1176))\n","        for i in range(640):\n","          for j in range(1176):\n","            locationPrior[i][j] = self.SLP(torch.from_numpy(a), THETA[i][j], 'predict')\n","        \n","        return locationPrior # NOTE: All cells are independent\n","    \n","    \n","    def eq11(self):\n","        '''\n","            Path Distribution: \n","            p(XM|X0, XT , Θt) = 1 −PI[(M) <-- (t˜=0)](1 − p(Xt˜|X0, XT , Θt))\n","        '''\n","        pass\n","    \n","    \n","    def eq12(self):\n","        '''\n","            Cost function to get best weighting params, i.e, a:\n","            J(a) = −Summation[ ζi ∈ Xj ] Summation[ Xj ∈ ζi ] log(p(X = Xj |X0, XT , Θt))\n","        '''\n","        pass\n","    \n","    # Goal Distribution XT Estimation ahead\n","    def eq13(self):\n","        '''\n","            p(Xt) ::= estimated distribution for the pedestrian’s state at time = t. \n","            p(X−t|X0, XT , Θt) ::= the distribution of that state obtained from prediction at t-1. \n","        \n","            [!] After Assumption: Independence\n","            Can obtain:\n","        \n","                pX− (X−t|X0, XT , Θt) ∝ pX− (X0, XT , Θt|X−t)p(X−t)\n","        \n","        '''\n","        pass\n","    \n","    \n","    def eq14(self):\n","        '''\n","            p(XT ) ∝ Integral of pX− (X0, XT , Θt|Xt).p(Xt).dX\n","            \n","            [+] Evaluated for the individual particles and the result is used for reweighting\n","            Next TODO: Unlikely particles are discarded and randomly resampled at other locations.\n","        '''\n","        pass\n","    \n","    \n","    def __init__(self, bb_Images, bb_cos):\n","        self.df = bb_Images\n","        self.dfBox = bb_cos\n","        self.grid = np.zeros(shape=(640, 1176)) # Grid\n","        self.fps = 30                          # fps\n","        self.X = []                            # Contains last t positions & orientations: (x_t, y_t, psi_t)\n","        self.distX = None                      # Contains X's distribution on grid\n","        self.uni = []                          # Contains unicycle vector of motion: u(vt, psi_t) \n","        self.distUni = None                    # Contains uni's distribution on grid as per X's co-ordinates\n","        self.Xt_given_Xt_1 = None              # Contains distribution: P(X_t | X_t-1)\n","        self.px0 = 0\n","        self.XT = None                         # Latent Variable: Gaussian Mixture Model + Particle Filter\n","        self.A = np.zeros(shape=(640, 1176))\n","        for key in self.df:\n","            self.compute_X(key)  # Watch 1 sec to estimate X"],"metadata":{"id":"9TBNTpjJIud0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DB1: First 30 frames do not convey all the information.\n","## DB2: "],"metadata":{"id":"9rX1QvlgU6xK"}},{"cell_type":"code","source":[""],"metadata":{"id":"GM5iBb-1I5OB"},"execution_count":null,"outputs":[]}]}